{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bikeshare Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# from ydata_profiling import ProfileReport\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are provided hourly rental data spanning two years. For this competition, the training set is comprised of the first 19 days of each month, while the test set is the 20th to the end of the month. You must predict the total count of bikes rented during each hour covered by the test set, using only information available prior to the rental period.\n",
    "\n",
    "Data Fields\n",
    "- datetime - hourly date + timestamp  \n",
    "- season \n",
    "    - 1 = spring, \n",
    "    - 2 = summer, \n",
    "    - 3 = fall, \n",
    "    - 4 = winter \n",
    "- holiday - whether the day is considered a holiday\n",
    "- workingday - whether the day is neither a weekend nor holiday\n",
    "- weather \n",
    "    - 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
    "    - 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
    "    - 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
    "    - 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog \n",
    "- temp - temperature in Celsius\n",
    "- atemp - \"feels like\" temperature in Celsius\n",
    "- humidity - relative humidity\n",
    "- windspeed - wind speed\n",
    "- casual - number of non-registered user rentals initiated\n",
    "- registered - number of registered user rentals initiated\n",
    "- count - number of total rentals <- PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  season  holiday  workingday  weather  temp   atemp  \\\n",
       "0  2011-01-01 00:00:00       1        0           0        1  9.84  14.395   \n",
       "1  2011-01-01 01:00:00       1        0           0        1  9.02  13.635   \n",
       "2  2011-01-01 02:00:00       1        0           0        1  9.02  13.635   \n",
       "3  2011-01-01 03:00:00       1        0           0        1  9.84  14.395   \n",
       "4  2011-01-01 04:00:00       1        0           0        1  9.84  14.395   \n",
       "\n",
       "   humidity  windspeed  count  \n",
       "0        81        0.0     16  \n",
       "1        80        0.0     40  \n",
       "2        80        0.0     32  \n",
       "3        75        0.0     13  \n",
       "4        75        0.0      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/train.csv')\n",
    "\n",
    "# Dropping casual and registered columns\n",
    "train_df.drop(['casual', 'registered'], axis=1, inplace=True)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-20 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.66</td>\n",
       "      <td>11.365</td>\n",
       "      <td>56</td>\n",
       "      <td>26.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-20 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.66</td>\n",
       "      <td>13.635</td>\n",
       "      <td>56</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-20 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.66</td>\n",
       "      <td>13.635</td>\n",
       "      <td>56</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-20 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>56</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-20 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>56</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  season  holiday  workingday  weather   temp   atemp  \\\n",
       "0  2011-01-20 00:00:00       1        0           1        1  10.66  11.365   \n",
       "1  2011-01-20 01:00:00       1        0           1        1  10.66  13.635   \n",
       "2  2011-01-20 02:00:00       1        0           1        1  10.66  13.635   \n",
       "3  2011-01-20 03:00:00       1        0           1        1  10.66  12.880   \n",
       "4  2011-01-20 04:00:00       1        0           1        1  10.66  12.880   \n",
       "\n",
       "   humidity  windspeed  \n",
       "0        56    26.0027  \n",
       "1        56     0.0000  \n",
       "2        56     0.0000  \n",
       "3        56    11.0014  \n",
       "4        56    11.0014  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('../data/test.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the profile report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_df = pd.concat([train_df.drop(columns=[\"count\"]), test_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(profile_df, title='Pandas Profiling Report', explorative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67509a94decc46888ddb4040ffdfa431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuel/anaconda3/envs/bikeshare/lib/python3.11/site-packages/ydata_profiling/model/correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.\n",
      "To hide this warning, disable the calculation\n",
      "(using `df.profile_report(correlations={\"auto\": {\"calculate\": False}})`\n",
      "If this is problematic for your use case, please report this as an issue:\n",
      "https://github.com/ydataai/ydata-profiling/issues\n",
      "(include the error message: 'cannot reindex on an axis with duplicate labels')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa67b692d6f4a7db03da23da76497c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0058ea137b03406a987010be7b9cddd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea03f1931a4424f9fc673def6577c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "profile.to_file(\"./reports/eda-profile.html\")\n",
    "_ = os.system(\"open ./reports/eda-profile.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training without Using Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuel/anaconda3/envs/bikeshare/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Running Tabular Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"autogluon\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.11.8\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.5.0: Wed May  1 20:12:58 PDT 2024; root:xnu-10063.121.3~5/RELEASE_ARM64_T6000\n",
      "CPU Count:          8\n",
      "Memory Avail:       6.05 GB / 16.00 GB (37.8%)\n",
      "Disk Space Avail:   51.70 GB / 460.43 GB (11.2%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 150s of the 600s of remaining time (25%).\n",
      "2024-07-07 16:37:09,911\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "/Users/samuel/anaconda3/envs/bikeshare/lib/python3.11/site-packages/autogluon/tabular/predictor/predictor.py:1242: UserWarning: Failed to use ray for memory safe fits. Falling back to normal fit. Error: ValueError('ray==2.31.0 detected. 2.10.0 <= ray < 2.11.0 is required. You can use pip to install certain version of ray `pip install ray==2.10.0` ')\n",
      "  stacked_overfitting = self._sub_fit_memory_save_wrapper(\n",
      "\t\tContext path: \"autogluon/ds_sub_fit/sub_fit_ho\"\n",
      "Running DyStack sub-fit ...\n",
      "Beginning AutoGluon training ... Time limit = 148s\n",
      "AutoGluon will save models to \"autogluon/ds_sub_fit/sub_fit_ho\"\n",
      "Train Data Rows:    9676\n",
      "Train Data Columns: 9\n",
      "Label Column:       count\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6086.67 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.29 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      : 3 | ['temp', 'atemp', 'windspeed']\n",
      "\t\t('int', [])                        : 5 | ['season', 'holiday', 'workingday', 'weather', 'humidity']\n",
      "\t\t('object', ['datetime_as_object']) : 1 | ['datetime']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 3 | ['temp', 'atemp', 'windspeed']\n",
      "\t\t('int', [])                  : 3 | ['season', 'weather', 'humidity']\n",
      "\t\t('int', ['bool'])            : 2 | ['holiday', 'workingday']\n",
      "\t\t('int', ['datetime_as_int']) : 5 | ['datetime', 'datetime.year', 'datetime.month', 'datetime.day', 'datetime.dayofweek']\n",
      "\t0.0s = Fit runtime\n",
      "\t9 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.83 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 98.87s of the 148.34s of remaining time.\n",
      "\t-107.3513\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 93.15s of the 142.62s of remaining time.\n",
      "\t-89.9096\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 93.12s of the 142.59s of remaining time.\n",
      "Will use sequential fold fitting strategy because import of ray failed. Reason: ray==2.31.0 detected. 2.10.0 <= ray < 2.11.0 is required. You can use pip to install certain version of ray `pip install ray==2.10.0` \n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "/Users/samuel/anaconda3/envs/bikeshare/lib/python3.11/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 129.692\n",
      "[2000]\tvalid_set's rmse: 128.562\n",
      "[3000]\tvalid_set's rmse: 128.461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 3482. Best iteration is:\n",
      "\t[2833]\tvalid_set's rmse: 128.314\n",
      "\tTime limit exceeded... Skipping LightGBMXT_BAG_L1.\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 81.28s of the 130.75s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 129.274\n",
      "[1000]\tvalid_set's rmse: 129.285\n",
      "[1000]\tvalid_set's rmse: 135.098\n",
      "[1000]\tvalid_set's rmse: 124.896\n",
      "[1000]\tvalid_set's rmse: 134.058\n",
      "[1000]\tvalid_set's rmse: 134.479\n",
      "[1000]\tvalid_set's rmse: 136.511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-131.8496\t = Validation score   (-root_mean_squared_error)\n",
      "\t25.18s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 55.73s of the 105.2s of remaining time.\n",
      "\t-119.5502\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.02s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 52.26s of the 101.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 2232.\n",
      "\tRan out of time, early stopping on iteration 2650.\n",
      "\tRan out of time, early stopping on iteration 3312.\n",
      "\tRan out of time, early stopping on iteration 3440.\n",
      "\tRan out of time, early stopping on iteration 3596.\n",
      "\tRan out of time, early stopping on iteration 4016.\n",
      "\t-131.835\t = Validation score   (-root_mean_squared_error)\n",
      "\t49.64s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 2.57s of the 52.04s of remaining time.\n",
      "\t-126.0427\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1.44s of the 50.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L1.\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 0.32s of the 49.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping XGBoost_BAG_L1.\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 0.06s of the 49.53s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 148.35s of the 48.56s of remaining time.\n",
      "\tEnsemble Weights: {'KNeighborsDist_BAG_L1': 1.0}\n",
      "\t-89.9096\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 48.54s of the 48.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 68.4396\n",
      "[1000]\tvalid_set's rmse: 70.4375\n",
      "[1000]\tvalid_set's rmse: 78.3282\n",
      "[1000]\tvalid_set's rmse: 72.9126\n",
      "[2000]\tvalid_set's rmse: 72.8003\n",
      "[1000]\tvalid_set's rmse: 75.2908\n",
      "[1000]\tvalid_set's rmse: 76.558\n",
      "[1000]\tvalid_set's rmse: 70.1196\n",
      "[1000]\tvalid_set's rmse: 74.4144\n",
      "[2000]\tvalid_set's rmse: 73.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-73.1365\t = Validation score   (-root_mean_squared_error)\n",
      "\t38.89s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 9.08s of the 9.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 290. Best iteration is:\n",
      "\t[288]\tvalid_set's rmse: 62.5063\n",
      "\tRan out of time, early stopping on iteration 303. Best iteration is:\n",
      "\t[143]\tvalid_set's rmse: 65.2556\n",
      "\tRan out of time, early stopping on iteration 309. Best iteration is:\n",
      "\t[140]\tvalid_set's rmse: 70.5065\n",
      "\tRan out of time, early stopping on iteration 321. Best iteration is:\n",
      "\t[180]\tvalid_set's rmse: 68.5704\n",
      "\tRan out of time, early stopping on iteration 352. Best iteration is:\n",
      "\t[184]\tvalid_set's rmse: 67.7337\n",
      "\tRan out of time, early stopping on iteration 375. Best iteration is:\n",
      "\t[111]\tvalid_set's rmse: 71.169\n",
      "\tRan out of time, early stopping on iteration 414. Best iteration is:\n",
      "\t[145]\tvalid_set's rmse: 65.0681\n",
      "\tRan out of time, early stopping on iteration 501. Best iteration is:\n",
      "\t[224]\tvalid_set's rmse: 69.408\n",
      "\t-67.5854\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.67s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 148.35s of the 0.22s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L2': 0.96, 'LightGBMXT_BAG_L2': 0.04}\n",
      "\t-67.5823\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 148.22s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 3148.0 rows/s (1210 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"autogluon/ds_sub_fit/sub_fit_ho\")\n",
      "Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                    model  score_holdout   score_val              eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0     WeightedEnsemble_L3     -68.910132  -67.582260  root_mean_squared_error        0.855299       0.896469  126.149459                 0.000794                0.000216           0.028922            3       True         10\n",
      "1         LightGBM_BAG_L2     -68.977330  -67.585360  root_mean_squared_error        0.589435       0.725936   87.226428                 0.050367                0.027990           8.673030            2       True          9\n",
      "2       LightGBMXT_BAG_L2     -71.620338  -73.136466  root_mean_squared_error        0.804138       0.868263  117.447507                 0.265070                0.170317          38.894109            2       True          8\n",
      "3   KNeighborsDist_BAG_L1     -92.326969  -89.909634  root_mean_squared_error        0.018256       0.015133    0.004593                 0.018256                0.015133           0.004593            1       True          2\n",
      "4     WeightedEnsemble_L2     -92.326969  -89.909634  root_mean_squared_error        0.019506       0.015409    0.013954                 0.001250                0.000276           0.009361            2       True          7\n",
      "5   KNeighborsUnif_BAG_L1    -109.825895 -107.351259  root_mean_squared_error        0.016095       0.029325    0.004401                 0.016095                0.029325           0.004401            1       True          1\n",
      "6  RandomForestMSE_BAG_L1    -118.498559 -119.550169  root_mean_squared_error        0.135713       0.279004    3.023742                 0.135713                0.279004           3.023742            1       True          4\n",
      "7    ExtraTreesMSE_BAG_L1    -126.166360 -126.042651  root_mean_squared_error        0.173395       0.261606    0.702043                 0.173395                0.261606           0.702043            1       True          6\n",
      "8         LightGBM_BAG_L1    -130.706758 -131.849580  root_mean_squared_error        0.159910       0.097931   25.181943                 0.159910                0.097931          25.181943            1       True          3\n",
      "9         CatBoost_BAG_L1    -131.117390 -131.834973  root_mean_squared_error        0.035699       0.014948   49.636677                 0.035699                0.014948          49.636677            1       True          5\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t151s\t = DyStack   runtime |\t449s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 449s\n",
      "AutoGluon will save models to \"autogluon\"\n",
      "Train Data Rows:    10886\n",
      "Train Data Columns: 9\n",
      "Label Column:       count\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6180.75 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.45 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      : 3 | ['temp', 'atemp', 'windspeed']\n",
      "\t\t('int', [])                        : 5 | ['season', 'holiday', 'workingday', 'weather', 'humidity']\n",
      "\t\t('object', ['datetime_as_object']) : 1 | ['datetime']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 3 | ['temp', 'atemp', 'windspeed']\n",
      "\t\t('int', [])                  : 3 | ['season', 'weather', 'humidity']\n",
      "\t\t('int', ['bool'])            : 2 | ['holiday', 'workingday']\n",
      "\t\t('int', ['datetime_as_int']) : 5 | ['datetime', 'datetime.year', 'datetime.month', 'datetime.day', 'datetime.dayofweek']\n",
      "\t0.0s = Fit runtime\n",
      "\t9 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.93 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 299.37s of the 449.17s of remaining time.\n",
      "\t-101.5882\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 299.33s of the 449.12s of remaining time.\n",
      "\t-84.1464\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 299.28s of the 449.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 131.684\n",
      "[2000]\tvalid_set's rmse: 130.67\n",
      "[3000]\tvalid_set's rmse: 130.626\n",
      "[1000]\tvalid_set's rmse: 135.592\n",
      "[1000]\tvalid_set's rmse: 133.481\n",
      "[2000]\tvalid_set's rmse: 132.323\n",
      "[3000]\tvalid_set's rmse: 131.618\n",
      "[4000]\tvalid_set's rmse: 131.443\n",
      "[5000]\tvalid_set's rmse: 131.265\n",
      "[6000]\tvalid_set's rmse: 131.277\n",
      "[7000]\tvalid_set's rmse: 131.443\n",
      "[1000]\tvalid_set's rmse: 128.503\n",
      "[2000]\tvalid_set's rmse: 127.654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 2986. Best iteration is:\n",
      "\t[2813]\tvalid_set's rmse: 127.244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 134.135\n",
      "[2000]\tvalid_set's rmse: 132.272\n",
      "[3000]\tvalid_set's rmse: 131.286\n",
      "[4000]\tvalid_set's rmse: 130.752\n",
      "[5000]\tvalid_set's rmse: 130.363\n",
      "[6000]\tvalid_set's rmse: 130.509\n",
      "[1000]\tvalid_set's rmse: 136.168\n",
      "[2000]\tvalid_set's rmse: 135.138\n",
      "[3000]\tvalid_set's rmse: 135.029\n",
      "[1000]\tvalid_set's rmse: 134.061\n",
      "[2000]\tvalid_set's rmse: 133.034\n",
      "[3000]\tvalid_set's rmse: 132.182\n",
      "[4000]\tvalid_set's rmse: 131.997\n",
      "[5000]\tvalid_set's rmse: 131.643\n",
      "[6000]\tvalid_set's rmse: 131.504\n",
      "[7000]\tvalid_set's rmse: 131.574\n",
      "[1000]\tvalid_set's rmse: 132.912\n",
      "[2000]\tvalid_set's rmse: 131.703\n",
      "[3000]\tvalid_set's rmse: 131.117\n",
      "[4000]\tvalid_set's rmse: 130.82\n",
      "[5000]\tvalid_set's rmse: 130.673\n",
      "[6000]\tvalid_set's rmse: 130.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-131.4948\t = Validation score   (-root_mean_squared_error)\n",
      "\t255.91s\t = Training   runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 41.7s of the 191.5s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 360. Best iteration is:\n",
      "\t[360]\tvalid_set's rmse: 131.436\n",
      "\tRan out of time, early stopping on iteration 698. Best iteration is:\n",
      "\t[695]\tvalid_set's rmse: 133.551\n",
      "\tRan out of time, early stopping on iteration 675. Best iteration is:\n",
      "\t[675]\tvalid_set's rmse: 131.674\n",
      "\tRan out of time, early stopping on iteration 874. Best iteration is:\n",
      "\t[771]\tvalid_set's rmse: 126.67\n",
      "\tRan out of time, early stopping on iteration 777. Best iteration is:\n",
      "\t[766]\tvalid_set's rmse: 131.739\n",
      "\tRan out of time, early stopping on iteration 865. Best iteration is:\n",
      "\t[758]\tvalid_set's rmse: 133.592\n",
      "\tRan out of time, early stopping on iteration 913. Best iteration is:\n",
      "\t[898]\tvalid_set's rmse: 132.053\n",
      "\tRan out of time, early stopping on iteration 1012. Best iteration is:\n",
      "\t[999]\tvalid_set's rmse: 130.618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 130.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-131.4324\t = Validation score   (-root_mean_squared_error)\n",
      "\t39.87s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 1.51s of the 151.3s of remaining time.\n",
      "\t-116.542\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.87s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 149.0s of remaining time.\n",
      "\tEnsemble Weights: {'KNeighborsDist_BAG_L1': 1.0}\n",
      "\t-84.1464\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 148.99s of the 148.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 60.597\n",
      "[2000]\tvalid_set's rmse: 59.5748\n",
      "[1000]\tvalid_set's rmse: 61.4527\n",
      "[2000]\tvalid_set's rmse: 60.1446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 2307. Best iteration is:\n",
      "\t[2052]\tvalid_set's rmse: 60.0915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 64.1794\n",
      "[2000]\tvalid_set's rmse: 63.0111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 2395. Best iteration is:\n",
      "\t[2304]\tvalid_set's rmse: 62.9171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 64.2891\n",
      "[2000]\tvalid_set's rmse: 62.9486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 2918. Best iteration is:\n",
      "\t[2453]\tvalid_set's rmse: 62.7896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 59.0302\n",
      "[2000]\tvalid_set's rmse: 57.5905\n",
      "[1000]\tvalid_set's rmse: 62.8332\n",
      "[2000]\tvalid_set's rmse: 61.2736\n",
      "[1000]\tvalid_set's rmse: 63.068\n",
      "[2000]\tvalid_set's rmse: 62.3601\n",
      "[3000]\tvalid_set's rmse: 62.3717\n",
      "[1000]\tvalid_set's rmse: 58.4155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-60.5704\t = Validation score   (-root_mean_squared_error)\n",
      "\t125.64s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 22.47s of the 22.46s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 411. Best iteration is:\n",
      "\t[154]\tvalid_set's rmse: 53.9719\n",
      "\tRan out of time, early stopping on iteration 415. Best iteration is:\n",
      "\t[339]\tvalid_set's rmse: 52.7536\n",
      "\tRan out of time, early stopping on iteration 372. Best iteration is:\n",
      "\t[249]\tvalid_set's rmse: 54.7015\n",
      "\tRan out of time, early stopping on iteration 383. Best iteration is:\n",
      "\t[199]\tvalid_set's rmse: 55.3363\n",
      "\tRan out of time, early stopping on iteration 417. Best iteration is:\n",
      "\t[306]\tvalid_set's rmse: 54.765\n",
      "\tRan out of time, early stopping on iteration 444. Best iteration is:\n",
      "\t[255]\tvalid_set's rmse: 56.0249\n",
      "\t-54.5864\t = Validation score   (-root_mean_squared_error)\n",
      "\t20.63s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 1.65s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L2': 0.952, 'LightGBMXT_BAG_L2': 0.048}\n",
      "\t-54.5697\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 447.6s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1288.3 rows/s (1361 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"autogluon\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(\n",
    "        label='count',\n",
    "        path='autogluon',\n",
    "        eval_metric='root_mean_squared_error',\n",
    "    ).fit(\n",
    "        train_df,\n",
    "        time_limit=600,\n",
    "        presets='best_quality'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Showing the Leatherboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>-54.569714</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.292876</td>\n",
       "      <td>443.947090</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.011255</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>-54.586355</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.010519</td>\n",
       "      <td>318.299719</td>\n",
       "      <td>0.039332</td>\n",
       "      <td>20.634286</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBMXT_BAG_L2</td>\n",
       "      <td>-60.570375</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.253296</td>\n",
       "      <td>423.301549</td>\n",
       "      <td>0.282109</td>\n",
       "      <td>125.636116</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>-84.146423</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.014645</td>\n",
       "      <td>0.009696</td>\n",
       "      <td>0.014645</td>\n",
       "      <td>0.009696</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-84.146423</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.014847</td>\n",
       "      <td>0.021625</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.011929</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>-101.588176</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.014143</td>\n",
       "      <td>0.006946</td>\n",
       "      <td>0.014143</td>\n",
       "      <td>0.006946</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestMSE_BAG_L1</td>\n",
       "      <td>-116.542032</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.241228</td>\n",
       "      <td>1.870387</td>\n",
       "      <td>0.241228</td>\n",
       "      <td>1.870387</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>-131.432362</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.088231</td>\n",
       "      <td>39.867387</td>\n",
       "      <td>0.088231</td>\n",
       "      <td>39.867387</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>-131.494795</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.612940</td>\n",
       "      <td>255.911016</td>\n",
       "      <td>0.612940</td>\n",
       "      <td>255.911016</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model   score_val              eval_metric  pred_time_val  \\\n",
       "0     WeightedEnsemble_L3  -54.569714  root_mean_squared_error       1.292876   \n",
       "1         LightGBM_BAG_L2  -54.586355  root_mean_squared_error       1.010519   \n",
       "2       LightGBMXT_BAG_L2  -60.570375  root_mean_squared_error       1.253296   \n",
       "3   KNeighborsDist_BAG_L1  -84.146423  root_mean_squared_error       0.014645   \n",
       "4     WeightedEnsemble_L2  -84.146423  root_mean_squared_error       0.014847   \n",
       "5   KNeighborsUnif_BAG_L1 -101.588176  root_mean_squared_error       0.014143   \n",
       "6  RandomForestMSE_BAG_L1 -116.542032  root_mean_squared_error       0.241228   \n",
       "7         LightGBM_BAG_L1 -131.432362  root_mean_squared_error       0.088231   \n",
       "8       LightGBMXT_BAG_L1 -131.494795  root_mean_squared_error       0.612940   \n",
       "\n",
       "     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0  443.947090                0.000248           0.011255            3   \n",
       "1  318.299719                0.039332          20.634286            2   \n",
       "2  423.301549                0.282109         125.636116            2   \n",
       "3    0.009696                0.014645           0.009696            1   \n",
       "4    0.021625                0.000202           0.011929            2   \n",
       "5    0.006946                0.014143           0.006946            1   \n",
       "6    1.870387                0.241228           1.870387            1   \n",
       "7   39.867387                0.088231          39.867387            1   \n",
       "8  255.911016                0.612940         255.911016            1   \n",
       "\n",
       "   can_infer  fit_order  \n",
       "0       True          9  \n",
       "1       True          8  \n",
       "2       True          7  \n",
       "3       True          2  \n",
       "4       True          6  \n",
       "5       True          1  \n",
       "6       True          5  \n",
       "7       True          4  \n",
       "8       True          3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    display(predictor.leaderboard(silent=True))\n",
    "except:\n",
    "    predictor = TabularPredictor.load('autogluon')\n",
    "    display(predictor.leaderboard(silent=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Predictions on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    34.273094\n",
       "1    43.230057\n",
       "2    46.590622\n",
       "3    50.979973\n",
       "4    51.777607\n",
       "Name: count, dtype: float32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = predictor.predict(test_df)\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6493.000000\n",
       "mean       98.326591\n",
       "std        88.796036\n",
       "min       -10.711480\n",
       "25%        16.453503\n",
       "50%        62.550030\n",
       "75%       169.153320\n",
       "max       370.938568\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identifying negative predictions\n",
    "predictions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9 negative predictions to set to zero.\n"
     ]
    }
   ],
   "source": [
    "# Counting negative predictions\n",
    "negative_prediction_count = (predictions < 0).sum()\n",
    "\n",
    "print(f\"There are {negative_prediction_count} negative predictions to set to zero.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6493.000000\n",
       "mean       98.332489\n",
       "std        88.789307\n",
       "min         0.000000\n",
       "25%        16.453503\n",
       "50%        62.550030\n",
       "75%       169.153320\n",
       "max       370.938568\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting negative predictions to zero\n",
    "predictions[predictions < 0] = 0\n",
    "\n",
    "predictions.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Setting up for Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-20 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-20 01:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-20 02:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-20 03:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-20 04:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  count\n",
       "0  2011-01-20 00:00:00      0\n",
       "1  2011-01-20 01:00:00      0\n",
       "2  2011-01-20 02:00:00      0\n",
       "3  2011-01-20 03:00:00      0\n",
       "4  2011-01-20 04:00:00      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(6493, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = pd.read_csv('../data/sampleSubmission.csv')\n",
    "display(submission_df.head())\n",
    "submission_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-20 00:00:00</td>\n",
       "      <td>34.273094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-20 01:00:00</td>\n",
       "      <td>43.230057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-20 02:00:00</td>\n",
       "      <td>46.590622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-20 03:00:00</td>\n",
       "      <td>50.979973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-20 04:00:00</td>\n",
       "      <td>51.777607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime      count\n",
       "0  2011-01-20 00:00:00  34.273094\n",
       "1  2011-01-20 01:00:00  43.230057\n",
       "2  2011-01-20 02:00:00  46.590622\n",
       "3  2011-01-20 03:00:00  50.979973\n",
       "4  2011-01-20 04:00:00  51.777607"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(6493, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df['count'] = predictions\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "display(submission_df.head())\n",
    "submission_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Submitting Initial Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WeightedEnsemble_L3'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the best model name\n",
    "best_model = predictor.model_best\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 188k/188k [00:00<00:00, 436kB/s]\n",
      "Successfully submitted to Bike Sharing Demand"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c bike-sharing-demand -f submission.csv -m f\"irst submission with {best_model}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileName        date                 description                                status    publicScore  privateScore  \n",
      "--------------  -------------------  -----------------------------------------  --------  -----------  ------------  \n",
      "submission.csv  2024-07-07 21:14:45  first submission with WeightedEnsemble_L3  complete  1.84764      1.84764       \n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submissions -c bike-sharing-demand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF NOTEBOOK"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bikeshare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
