{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIKESHARE EDA & PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are provided hourly rental data spanning two years. For this competition, the training set is comprised of the first 19 days of each month, while the test set is the 20th to the end of the month. You must predict the total count of bikes rented during each hour covered by the test set, using only information available prior to the rental period.\n",
    "\n",
    "Data Fields\n",
    "- datetime - hourly date + timestamp  \n",
    "- season \n",
    "    - 1 = spring, \n",
    "    - 2 = summer, \n",
    "    - 3 = fall, \n",
    "    - 4 = winter \n",
    "- holiday - whether the day is considered a holiday\n",
    "- workingday - whether the day is neither a weekend nor holiday\n",
    "- weather \n",
    "    - 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
    "    - 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
    "    - 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
    "    - 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog \n",
    "- temp - temperature in Celsius\n",
    "- atemp - \"feels like\" temperature in Celsius\n",
    "- humidity - relative humidity\n",
    "- windspeed - wind speed\n",
    "- casual - number of non-registered user rentals initiated\n",
    "- registered - number of registered user rentals initiated\n",
    "- count - number of total rentals <- PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader()\n",
    "\n",
    "train_df, test_df = loader.get_train_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_df = train_df[['datetime', 'casual', 'registered', 'count', 'season']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the casual and registered columns\n",
    "train_df.drop(['casual', 'registered'], axis=1, inplace=True)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving checkpoint for the no feature engineering autogluon model predictions\n",
    "loader.save_feature_engineered_data(train_df, test_df, \"no_data_engineering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting Null Values\n",
    "\n",
    "No null values found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting Distribution and Correlation\n",
    "\n",
    "We can see that the big drivers for the count of bike rentals are the temperature and the humidity. The temperature and the \"feels like\" temperature are highly correlated, so we can drop one of them. And since the atemp is less correlated with count, it will be the one to be dropped. The windspeed and the humidity are also correlated, but not as much as the temperature and the \"feels like\" temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = train_df.drop(columns=[\"count\"]).hist(figsize=(20, 10), bins=20, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap of correlations\n",
    "correlation_df = train_df.drop(columns=[\"datetime\"]).corr()\n",
    "correlation_df.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify correlation higher than 0.9\n",
    "correlation_threshold = 0.9\n",
    "correlation_matrix = correlation_df.abs() > correlation_threshold\n",
    "\n",
    "# Find pairs of features with high correlation\n",
    "correlation_matrix = correlation_matrix.stack()\n",
    "correlation_matrix = correlation_matrix[correlation_matrix]\n",
    "correlation_matrix = correlation_matrix.reset_index()\n",
    "correlation_matrix.columns = [\"Feature 1\", \"Feature 2\", \"Correlation\"]\n",
    "\n",
    "# Where Feature 1 is not equal to Feature 2\n",
    "correlation_matrix = correlation_matrix[correlation_matrix[\"Feature 1\"] != correlation_matrix[\"Feature 2\"]]\n",
    "display(correlation_matrix)\n",
    "\n",
    "# Identify which feature correlates more with count\n",
    "correlation_with_count = correlation_df[\"count\"].abs().sort_values(ascending=False)\n",
    "correlation_with_count.to_frame().style.background_gradient(cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping atemp since it is highly correlated with temp\n",
    "train_df.drop(columns=[\"atemp\"], inplace=True)\n",
    "test_df.drop(columns=[\"atemp\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting Trend of Data\n",
    "\n",
    "We can observe some seasonality in the data, as well as some upward trend and increase in variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set count to zero where season is not 1 using assign\n",
    "def set_count_to_zero(count, season, season_value):\n",
    "    if season != season_value:\n",
    "        return 0\n",
    "    return count\n",
    "\n",
    "train_df.assign(count=lambda x: x.apply(lambda row: set_count_to_zero(row[\"count\"], row[\"season\"], 1), axis=1))[\"count\"].plot(figsize=(20, 10), label=\"Spring\", color=\"green\")\n",
    "train_df.assign(count=lambda x: x.apply(lambda row: set_count_to_zero(row[\"count\"], row[\"season\"], 2), axis=1))[\"count\"].plot(label=\"Summer\", color=\"orange\")\n",
    "train_df.assign(count=lambda x: x.apply(lambda row: set_count_to_zero(row[\"count\"], row[\"season\"], 3), axis=1))[\"count\"].plot(label=\"Fall\", color=\"goldenrod\")\n",
    "train_df.assign(count=lambda x: x.apply(lambda row: set_count_to_zero(row[\"count\"], row[\"season\"], 4), axis=1))[\"count\"].plot(label=\"Winter\", color=\"cornflowerblue\")\n",
    "\n",
    "\n",
    "# Smoothing the trend\n",
    "trend_df.set_index(\"datetime\")[\"count\"].rolling(window=100).mean().plot(figsize=(20, 10), label=\"Count Smoothed\", color=\"blueviolet\")\n",
    "\n",
    "# Least square line of count .plot\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = np.arange(len(trend_df)).reshape(-1, 1)\n",
    "y = trend_df[\"count\"]\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "trend_df.loc[:, \"trend\"] = model.predict(X)\n",
    "\n",
    "trend_df.set_index(\"datetime\")[\"trend\"].plot(figsize=(20, 10), color=\"red\", label=\"Trend\", linestyle=\"--\")\n",
    "\n",
    "# Add legend to the plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_ = plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting Category Types\n",
    "\n",
    "Weather and Season are categorical variables. These need to be converted to dummy variables, or set as type category. We are setting them to category type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the function to use on the bikeshare notebook\n",
    "loader.set_as_category(columns=[\"season\", \"weather\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separating the datetime column into year, month, day, hour and weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create day of of the week feature\n",
    "train_df[\"datetime\"] = pd.to_datetime(train_df[\"datetime\"])\n",
    "train_df[\"day_of_week\"] = train_df[\"datetime\"].dt.dayofweek.astype(\"category\")\n",
    "\n",
    "test_df[\"datetime\"] = pd.to_datetime(test_df[\"datetime\"])\n",
    "test_df[\"day_of_week\"] = test_df[\"datetime\"].dt.dayofweek.astype(\"category\")\n",
    "\n",
    "test_df[\"datetime\"] = pd.to_datetime(test_df[\"datetime\"])\n",
    "test_df[\"day_of_week\"] = test_df[\"datetime\"].dt.dayofweek.astype(\"category\")\n",
    "\n",
    "\n",
    "# Sparating hour and minute from datetime\n",
    "train_df[\"hour\"] = train_df[\"datetime\"].dt.hour\n",
    "train_df[\"date\"] = train_df[\"datetime\"].dt.date\n",
    "\n",
    "test_df[\"hour\"] = test_df[\"datetime\"].dt.hour\n",
    "test_df[\"date\"] = test_df[\"datetime\"].dt.date\n",
    "\n",
    "test_df[\"hour\"] = test_df[\"datetime\"].dt.hour\n",
    "test_df[\"date\"] = test_df[\"datetime\"].dt.date\n",
    "\n",
    "# Dropping datetime column\n",
    "train_df.drop(columns=[\"datetime\"], inplace=True)\n",
    "test_df.drop(columns=[\"datetime\"], inplace=True)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving checkpoint for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.save_feature_engineered_data(train_df, test_df, checkpoint_name=\"hyperparameter_tuning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engineering New Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmenting Into Day Periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.hour.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy_bins(train_df, test_df, column, bins, labels):\n",
    "    \"\"\"\n",
    "    Create bins for the column and create dummy variables for the bins\n",
    "    :param train_df: DataFrame to create the bins\n",
    "    :param column: Column to create the bins\n",
    "    :param bins: Bins to create\n",
    "    :param labels: Labels for the bins\n",
    "    :return: DataFrame with the bins\n",
    "\n",
    "    Sets a global variable trend_df to the DataFrame with categories for the trend graphs.\n",
    "    Use `show_line_trend()` to show the trend graph\n",
    "    \"\"\"\n",
    "    train_df[f\"{column}_bins\"] = pd.cut(train_df[column], bins=bins, labels=labels, include_lowest=True)\n",
    "    test_df[f\"{column}_bins\"] = pd.cut(test_df[column], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "    global trend_df\n",
    "    trend_df = train_df[[\"date\", f\"{column}_bins\", \"count\"]]\n",
    "    trend_df[\"date\"] = pd.to_datetime(trend_df[\"date\"]).dt.date\n",
    "    train_df = pd.get_dummies(train_df, columns=[f\"{column}_bins\"], drop_first=False)\n",
    "    test_df = pd.get_dummies(test_df, columns=[f\"{column}_bins\"], drop_first=False)\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = create_dummy_bins(train_df, test_df, \"hour\", bins=[0, 6, 12, 18, 24], labels=[\"night\", \"morning\", \"afternoon\", \"evening\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heat map of the correlation\n",
    "def show_correlation_heatmap():\n",
    "    \"\"\"\n",
    "    Show the correlation heatmap of the train_df DataFrame, dropping the date column but not inplace.\n",
    "    :params: None\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    correlation_df = train_df.drop(columns=[\"date\"]).corr()\n",
    "    correlation_df = correlation_df[[\"count\"]].abs().sort_values(\"count\", ascending=False).style.background_gradient(cmap='coolwarm')\n",
    "    \n",
    "    display(correlation_df)\n",
    "\n",
    "show_correlation_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn line plot of day_period\n",
    "import seaborn as sns\n",
    "\n",
    "def show_line_trend(hue):\n",
    "    \"\"\"\n",
    "    Show the trend of the count column in the trend_df DataFrame.\n",
    "\n",
    "    :param hue: Column to use as hue in the seaborn lineplot\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    sns.lineplot(data=trend_df, x=\"date\", y=\"count\", hue=hue)\n",
    "\n",
    "    # Smoothing the count\n",
    "    trend_df[\"count_smoothed\"] = trend_df[\"count\"].rolling(window=100).mean()\n",
    "\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    sns.lineplot(data=trend_df, x=\"date\", y=\"count_smoothed\", hue=hue)\n",
    "\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    sns.pointplot(data=trend_df.groupby(['date', hue]).agg({\"count\": sum}).reset_index().query(\"count > 0\"), x=\"date\", y=\"count\", hue=hue)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "show_line_trend(\"hour_bins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorizing Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.temp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = create_dummy_bins(train_df, test_df, \"temp\", bins=[0, 21, 26, 50], labels=[\"cold\", \"warm\", \"hot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_correlation_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_df.temp_bins.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_line_trend(\"temp_bins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorizing Wind Speed by Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.windspeed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = create_dummy_bins(train_df, test_df, \"windspeed\", bins=[0, 20, 30, 60], labels=[\"low\", \"medium\", \"high\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_correlation_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_line_trend(\"windspeed_bins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorizing Humidity by Buckets\n",
    "- Low Humidity: 0-20\n",
    "- Medium Humidity: 20-40\n",
    "- High Humidity: 40-60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.humidity.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = create_dummy_bins(train_df, test_df, \"humidity\", bins=[0, 62, 100], labels=[\"low\", \"high\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_correlation_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_line_trend(\"humidity_bins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving extra feature engineered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.save_feature_engineered_data(train_df, test_df, checkpoint_name=\"extra_feature_engineering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = train_df.drop(columns=[\"count\"]).hist(figsize=(20, 10), bins=20, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF NOTEBOOK"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bikeshare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
